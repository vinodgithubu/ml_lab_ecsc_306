{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOT GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=  0 cost=  0.959494\n",
      "iteration=  1000 cost=  0.180884\n",
      "iteration=  2000 cost=  0.134331\n",
      "iteration=  3000 cost=  0.108417\n",
      "iteration=  4000 cost=  0.090659\n",
      "iteration=  5000 cost=  0.0777345\n",
      "iteration=  6000 cost=  0.067937\n",
      "iteration=  7000 cost=  0.0602722\n",
      "iteration=  8000 cost=  0.0541226\n",
      "iteration=  9000 cost=  0.0490855\n",
      "iteration=  10000 cost=  0.0448881\n",
      "iteration=  11000 cost=  0.0413388\n",
      "iteration=  12000 cost=  0.0383002\n",
      "Validating output for NOT GATE\n",
      "[[ 0.95489216]\n",
      " [ 0.02997925]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.placeholder(tf.float32,shape=[None,1])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights=tf.Variable(tf.random_normal([1,1]),dtype=tf.float32)\n",
    "bias=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "multiply1=tf.add(tf.matmul(x,weights),bias)\n",
    "z=tf.nn.sigmoid(multiply1)\n",
    "\n",
    "\n",
    "cost=tf.reduce_mean((y*tf.log(z)+(1-y)*tf.log(1-z))*-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0],[1]])\n",
    "op=np.array([[1],[0]])\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(12001):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for NOT GATE\")\n",
    "    result=sess.run(z,feed_dict={x:inp})\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=  0 cost=  0.797819\n",
      "iteration=  1000 cost=  0.421295\n",
      "iteration=  2000 cost=  0.316662\n",
      "iteration=  3000 cost=  0.250593\n",
      "iteration=  4000 cost=  0.206044\n",
      "iteration=  5000 cost=  0.174242\n",
      "iteration=  6000 cost=  0.150497\n",
      "iteration=  7000 cost=  0.132145\n",
      "iteration=  8000 cost=  0.117572\n",
      "iteration=  9000 cost=  0.105744\n",
      "iteration=  10000 cost=  0.0959697\n",
      "iteration=  11000 cost=  0.0877697\n",
      "iteration=  12000 cost=  0.0808008\n",
      "Validating output for OR GATE\n",
      "[[ 0.16933417]\n",
      " [ 0.93315065]\n",
      " [ 0.93478131]\n",
      " [ 0.99898213]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights=tf.Variable(tf.random_normal([2,1]),dtype=tf.float32)\n",
    "bias=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "multiply1=tf.add(tf.matmul(x,weights),bias)\n",
    "z=tf.nn.sigmoid(multiply1)\n",
    "\n",
    "\n",
    "cost=tf.reduce_mean((y*tf.log(z)+(1-y)*tf.log(1-z))*-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "op=np.array([[0],[1],[1],[1]])\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(12001):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for OR GATE\")\n",
    "    result=sess.run(z,feed_dict={x:inp})\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AND GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights=tf.Variable(tf.random_normal([2,1]),dtype=tf.float32)\n",
    "bias=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "multiply1=tf.add(tf.matmul(x,weights),bias)\n",
    "z=tf.nn.sigmoid(multiply1)\n",
    "\n",
    "\n",
    "cost=tf.reduce_mean((y*tf.log(z)+(1-y)*tf.log(1-z))*-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "op=np.array([[0],[0],[0],[1]])\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(12001):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for AND GATE\")\n",
    "    result=sess.run(z,feed_dict={x:inp})\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mahantesh/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Iteration  0\n",
      "Iteration  4000\n",
      "Iteration  8000\n",
      "Iteration  12000\n",
      "Iteration  16000\n",
      "Iteration  20000\n",
      "Iteration  24000\n",
      "Iteration  28000\n",
      "Iteration  32000\n",
      "Iteration  36000\n",
      "Iteration  40000\n",
      "Iteration  44000\n",
      "Iteration  48000\n",
      "Iteration  52000\n",
      "Iteration  56000\n",
      "Iteration  60000\n",
      "Iteration  64000\n",
      "Iteration  68000\n",
      "Iteration  72000\n",
      "Iteration  76000\n",
      "[[ 0.03452263]\n",
      " [ 0.94507432]\n",
      " [ 0.94481105]\n",
      " [ 0.0591119 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_ = tf.placeholder(tf.float32, shape=[4,2], name=\"x-input\")\n",
    "y_ = tf.placeholder(tf.float32, shape=[4,1], name=\"y-input\")\n",
    "\n",
    "w1 = tf.Variable(tf.random_uniform([2,2], -1, 1), name=\"weight1\")\n",
    "w2 = tf.Variable(tf.random_uniform([2,1], -1, 1), name=\"weight2\")\n",
    "\n",
    "Bias1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "Bias2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "A2 = tf.sigmoid(tf.matmul(x_, w1) + Bias1)\n",
    "z = tf.sigmoid(tf.matmul(A2, w2) + Bias2)\n",
    "\n",
    "cost = tf.reduce_mean(( (y_ * tf.log(z)) + ((1 - y_) * tf.log(1.0 - z)) ) * -1)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "XOR_X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "XOR_Y = [[0],[1],[1],[0]]\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(80000):\n",
    "        sess.run(train_step, feed_dict={x_: XOR_X, y_: XOR_Y})\n",
    "        if i % 4000 == 0:\n",
    "            print('Iteration ', i)\n",
    "            result=sess.run(z, feed_dict={x_: XOR_X, y_: XOR_Y})\n",
    "            sess.run(w1)\n",
    "            sess.run(Bias1)\n",
    "            sess.run(w2)\n",
    "            sess.run(Bias2)\n",
    "print(result)            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-NOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mahantesh/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Iteration  0\n",
      "Iteration  4000\n",
      "Iteration  8000\n",
      "Iteration  12000\n",
      "Iteration  16000\n",
      "Iteration  20000\n",
      "Iteration  24000\n",
      "Iteration  28000\n",
      "Iteration  32000\n",
      "Iteration  36000\n",
      "Iteration  40000\n",
      "Iteration  44000\n",
      "Iteration  48000\n",
      "Iteration  52000\n",
      "Iteration  56000\n",
      "Iteration  60000\n",
      "Iteration  64000\n",
      "Iteration  68000\n",
      "Iteration  72000\n",
      "Iteration  76000\n",
      "[[ 0.97785747]\n",
      " [ 0.02043997]\n",
      " [ 0.02881064]\n",
      " [ 0.9813813 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_ = tf.placeholder(tf.float32, shape=[4,2], name=\"x-input\")\n",
    "y_ = tf.placeholder(tf.float32, shape=[4,1], name=\"y-input\")\n",
    "\n",
    "w1 = tf.Variable(tf.random_uniform([2,2], -1, 1), name=\"weight1\")\n",
    "w2 = tf.Variable(tf.random_uniform([2,1], -1, 1), name=\"weight2\")\n",
    "\n",
    "Bias1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "Bias2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "A2 = tf.sigmoid(tf.matmul(x_, w1) + Bias1)\n",
    "z = tf.sigmoid(tf.matmul(A2, w2) + Bias2)\n",
    "\n",
    "cost = tf.reduce_mean(( (y_ * tf.log(z)) + ((1 - y_) * tf.log(1.0 - z)) ) * -1)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "XOR_X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "XOR_Y = [[1],[0],[0],[1]]\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(80000):\n",
    "        sess.run(train_step, feed_dict={x_: XOR_X, y_: XOR_Y})\n",
    "        if i % 4000 == 0:\n",
    "            print('Iteration ', i)\n",
    "            result=sess.run(z, feed_dict={x_: XOR_X, y_: XOR_Y})\n",
    "            sess.run(w1)\n",
    "            sess.run(Bias1)\n",
    "            sess.run(w2)\n",
    "            sess.run(Bias2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
